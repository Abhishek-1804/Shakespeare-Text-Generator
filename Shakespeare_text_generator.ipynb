{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare text generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1nzJNtVln3WBJSTjyNpBXdbakLzYPoBBb",
      "authorship_tag": "ABX9TyOLHibGdn+6mCAN4Vcg1ccY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhidp55/Shakespeare-Text-Generator/blob/main/Shakespeare_text_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2gefdc-iiu4"
      },
      "source": [
        "#Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkihvZ9tF_p7"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout,GRU\n",
        "\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBUoGY_DilIK"
      },
      "source": [
        "#Reading data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBnXa55mGV1_"
      },
      "source": [
        "path_to_file = '/content/drive/MyDrive/Colab Notebooks/TF_2_Notebooks_and_Data/06-NLP-and-Text-Data/shakespeare.txt'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "051EodVfGcMi"
      },
      "source": [
        "text = open(path_to_file,'r').read()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO38WGQPGd-c",
        "outputId": "3d105237-2479-494b-aff0-27f4630d0317"
      },
      "source": [
        "len(text)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5445609"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGYTafxsGha3",
        "outputId": "d689e934-b7f3-4af6-c611-54ac7832996b"
      },
      "source": [
        "print(text[50000:50600])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ld may see my pleasure,\n",
            "  Sometime all full with feasting on your sight,\n",
            "  And by and by clean starved for a look,\n",
            "  Possessing or pursuing no delight\n",
            "  Save what is had, or must from you be took.\n",
            "    Thus do I pine and surfeit day by day,\n",
            "    Or gluttoning on all, or all away.\n",
            "\n",
            "\n",
            "                     76  \n",
            "  Why is my verse so barren of new pride?\n",
            "  So far from variation or quick change?\n",
            "  Why with the time do I not glance aside\n",
            "  To new-found methods, and to compounds strange?\n",
            "  Why write I still all one, ever the same,\n",
            "  And keep invention in a noted weed,\n",
            "  That every word doth almost tell m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qm9qHB4jipdo"
      },
      "source": [
        "#Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0APCXABGkcE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7e41dfc-d677-40f7-bb65-cbb6ae071ec1"
      },
      "source": [
        "vocab = sorted(set(text))\n",
        "len(vocab)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZBcCh9wGwtU"
      },
      "source": [
        "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEuhsAATGzOb"
      },
      "source": [
        "ind_to_char = np.array(vocab)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs6jgNYIG1nL"
      },
      "source": [
        "encoded_text = [char_to_ind[s] for s in text]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcYuI3dWG3jx"
      },
      "source": [
        "lines = '''\n",
        "Sometime all full with feasting on your sight,\n",
        "  And by and by clean starved for a look,\n",
        "  Possessing or pursuing no delight\n",
        "  Save what is had, or must from you be took.\n",
        "    Thus do I pine and surfeit day by day,\n",
        "    Or gluttoning on all, or all away.\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RGP2KpGHU4N",
        "outputId": "76740f71-09e0-486b-de89-2c358d1effde"
      },
      "source": [
        "len(lines)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1Kjf_yUHVlE"
      },
      "source": [
        "seq_len = 250"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BXR1KB8HZEJ",
        "outputId": "79c4e2c3-58e6-4b00-ef9d-7f9d55a329e3"
      },
      "source": [
        "total_num_seq = len(text)//(seq_len + 1)\n",
        "total_num_seq"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "21695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX-ME78MHaoY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da84cc3c-3661-4372-cf75-88d85985a821"
      },
      "source": [
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
        "len(char_dataset)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5445609"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLcW4YHEH0dE",
        "outputId": "732fae6f-7329-4cb6-de50-3480c11ec388"
      },
      "source": [
        "sequences = char_dataset.batch(seq_len+1, drop_remainder=True)\n",
        "sequences"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: (251,), types: tf.int32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI55mnCaH5LA"
      },
      "source": [
        "def create_seq_targets(seq):\n",
        "    input_txt = seq[:-1]\n",
        "    target_txt = seq[1:]\n",
        "    return input_txt, target_txt\n",
        "\n",
        "dataset = sequences.map(create_seq_targets)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjEBZhKxi_To"
      },
      "source": [
        "#Creating LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXlmjr2PIBPq"
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "# Buffer size to shuffle the dataset so it doesn't attempt to shuffle\n",
        "# the entire sequence in memory. Instead, it maintains a buffer in which it shuffles elements\n",
        "buffer_size = 8000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zeSIhpqIEEQ",
        "outputId": "637414d4-8d41-47e2-868e-3975b3970c4f"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((128, 250), (128, 250)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7e2uQ7DgI8eW"
      },
      "source": [
        "def sparse_cat_loss(y_true,y_pred):\n",
        "  return sparse_categorical_crossentropy(y_true, y_pred, from_logits=True) #Onehotencoding is done so from_logits = True"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PfBhxpRIFtC"
      },
      "source": [
        "vocab_size = len(vocab)\n",
        "\n",
        "# The embedding dimension\n",
        "embed_dim = 84\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_neurons = 1026"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5shoJapXI-oX"
      },
      "source": [
        "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocab_size, embed_dim,batch_input_shape=[batch_size, None]))\n",
        "    model.add(LSTM(rnn_neurons,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform',dropout=0.4))\n",
        "    model.add(LSTM(500,return_sequences=True,stateful=True,recurrent_initializer='glorot_uniform',dropout=0.4))\n",
        "    # Final Dense Layer to Predict\n",
        "    model.add(Dense(vocab_size))\n",
        "    model.compile(optimizer='adam', loss=sparse_cat_loss) \n",
        "    return model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LT3LiYHJBF6"
      },
      "source": [
        "model = create_model(\n",
        "  vocab_size = vocab_size,\n",
        "  embed_dim=embed_dim,\n",
        "  rnn_neurons=rnn_neurons,\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DR77dsiXJDAx",
        "outputId": "56f0ed6c-2921-4be7-9ec0-1b7f60e6cefd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (128, None, 84)           7056      \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (128, None, 1026)         4559544   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (128, None, 500)          3054000   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (128, None, 84)           42084     \n",
            "=================================================================\n",
            "Total params: 7,662,684\n",
            "Trainable params: 7,662,684\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKraaL_RkJ_D"
      },
      "source": [
        "##Example predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jwnwz_HGiDj-",
        "outputId": "7579f18f-7681-4415-f421-6bbdfd08b005"
      },
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "\n",
        "  # Predict off some random batch\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "\n",
        "  # Display the dimensions of the predictions\n",
        "  print(example_batch_predictions.shape, \" <=== (batch_size, sequence_length, vocab_size)\")\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(128, 250, 84)  <=== (batch_size, sequence_length, vocab_size)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdCqIf5MiEnG"
      },
      "source": [
        "# example_batch_predictions"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5HnlTvXuiIxP",
        "outputId": "11c0d974-2d81-4b68-ef10-26b5f7fcddbd"
      },
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(250, 1), dtype=int64, numpy=\n",
              "array([[16],\n",
              "       [14],\n",
              "       [59],\n",
              "       [64],\n",
              "       [82],\n",
              "       [66],\n",
              "       [13],\n",
              "       [11],\n",
              "       [14],\n",
              "       [82],\n",
              "       [56],\n",
              "       [36],\n",
              "       [79],\n",
              "       [31],\n",
              "       [53],\n",
              "       [47],\n",
              "       [59],\n",
              "       [ 0],\n",
              "       [26],\n",
              "       [ 0],\n",
              "       [13],\n",
              "       [17],\n",
              "       [48],\n",
              "       [75],\n",
              "       [59],\n",
              "       [13],\n",
              "       [43],\n",
              "       [67],\n",
              "       [59],\n",
              "       [15],\n",
              "       [27],\n",
              "       [29],\n",
              "       [14],\n",
              "       [79],\n",
              "       [20],\n",
              "       [36],\n",
              "       [77],\n",
              "       [83],\n",
              "       [24],\n",
              "       [ 6],\n",
              "       [77],\n",
              "       [73],\n",
              "       [59],\n",
              "       [68],\n",
              "       [59],\n",
              "       [10],\n",
              "       [67],\n",
              "       [ 6],\n",
              "       [ 2],\n",
              "       [29],\n",
              "       [49],\n",
              "       [77],\n",
              "       [34],\n",
              "       [10],\n",
              "       [28],\n",
              "       [ 0],\n",
              "       [21],\n",
              "       [57],\n",
              "       [70],\n",
              "       [32],\n",
              "       [65],\n",
              "       [ 4],\n",
              "       [14],\n",
              "       [69],\n",
              "       [69],\n",
              "       [15],\n",
              "       [26],\n",
              "       [63],\n",
              "       [64],\n",
              "       [47],\n",
              "       [13],\n",
              "       [39],\n",
              "       [52],\n",
              "       [71],\n",
              "       [39],\n",
              "       [62],\n",
              "       [ 0],\n",
              "       [62],\n",
              "       [43],\n",
              "       [79],\n",
              "       [65],\n",
              "       [28],\n",
              "       [35],\n",
              "       [83],\n",
              "       [79],\n",
              "       [34],\n",
              "       [21],\n",
              "       [51],\n",
              "       [24],\n",
              "       [43],\n",
              "       [52],\n",
              "       [ 3],\n",
              "       [26],\n",
              "       [32],\n",
              "       [22],\n",
              "       [52],\n",
              "       [ 5],\n",
              "       [61],\n",
              "       [83],\n",
              "       [81],\n",
              "       [ 3],\n",
              "       [ 1],\n",
              "       [42],\n",
              "       [46],\n",
              "       [74],\n",
              "       [47],\n",
              "       [14],\n",
              "       [46],\n",
              "       [52],\n",
              "       [ 5],\n",
              "       [72],\n",
              "       [83],\n",
              "       [82],\n",
              "       [14],\n",
              "       [61],\n",
              "       [12],\n",
              "       [52],\n",
              "       [53],\n",
              "       [28],\n",
              "       [76],\n",
              "       [55],\n",
              "       [21],\n",
              "       [67],\n",
              "       [56],\n",
              "       [ 6],\n",
              "       [74],\n",
              "       [ 9],\n",
              "       [63],\n",
              "       [77],\n",
              "       [19],\n",
              "       [38],\n",
              "       [75],\n",
              "       [55],\n",
              "       [53],\n",
              "       [69],\n",
              "       [78],\n",
              "       [62],\n",
              "       [65],\n",
              "       [ 7],\n",
              "       [47],\n",
              "       [58],\n",
              "       [19],\n",
              "       [24],\n",
              "       [47],\n",
              "       [ 2],\n",
              "       [19],\n",
              "       [54],\n",
              "       [ 9],\n",
              "       [80],\n",
              "       [53],\n",
              "       [67],\n",
              "       [74],\n",
              "       [ 1],\n",
              "       [34],\n",
              "       [80],\n",
              "       [11],\n",
              "       [25],\n",
              "       [70],\n",
              "       [51],\n",
              "       [72],\n",
              "       [15],\n",
              "       [63],\n",
              "       [37],\n",
              "       [28],\n",
              "       [45],\n",
              "       [53],\n",
              "       [28],\n",
              "       [40],\n",
              "       [76],\n",
              "       [17],\n",
              "       [49],\n",
              "       [82],\n",
              "       [68],\n",
              "       [71],\n",
              "       [ 4],\n",
              "       [70],\n",
              "       [50],\n",
              "       [61],\n",
              "       [81],\n",
              "       [25],\n",
              "       [34],\n",
              "       [62],\n",
              "       [17],\n",
              "       [26],\n",
              "       [ 1],\n",
              "       [15],\n",
              "       [39],\n",
              "       [66],\n",
              "       [24],\n",
              "       [29],\n",
              "       [61],\n",
              "       [74],\n",
              "       [40],\n",
              "       [ 3],\n",
              "       [13],\n",
              "       [36],\n",
              "       [56],\n",
              "       [63],\n",
              "       [19],\n",
              "       [74],\n",
              "       [27],\n",
              "       [37],\n",
              "       [10],\n",
              "       [40],\n",
              "       [38],\n",
              "       [16],\n",
              "       [43],\n",
              "       [81],\n",
              "       [69],\n",
              "       [46],\n",
              "       [10],\n",
              "       [78],\n",
              "       [69],\n",
              "       [30],\n",
              "       [14],\n",
              "       [13],\n",
              "       [ 9],\n",
              "       [ 5],\n",
              "       [36],\n",
              "       [44],\n",
              "       [ 0],\n",
              "       [33],\n",
              "       [20],\n",
              "       [54],\n",
              "       [ 5],\n",
              "       [43],\n",
              "       [44],\n",
              "       [52],\n",
              "       [64],\n",
              "       [43],\n",
              "       [40],\n",
              "       [82],\n",
              "       [48],\n",
              "       [73],\n",
              "       [83],\n",
              "       [82],\n",
              "       [19],\n",
              "       [62],\n",
              "       [48],\n",
              "       [66],\n",
              "       [76],\n",
              "       [18],\n",
              "       [79],\n",
              "       [21],\n",
              "       [41],\n",
              "       [44],\n",
              "       [31],\n",
              "       [78],\n",
              "       [63],\n",
              "       [14]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow1TuePxiKlp",
        "outputId": "a3a5354f-1971-45f1-9b36-8137bbea7810"
      },
      "source": [
        "# Reformat to not be a lists of lists\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([16, 14, 59, 64, 82, 66, 13, 11, 14, 82, 56, 36, 79, 31, 53, 47, 59,\n",
              "        0, 26,  0, 13, 17, 48, 75, 59, 13, 43, 67, 59, 15, 27, 29, 14, 79,\n",
              "       20, 36, 77, 83, 24,  6, 77, 73, 59, 68, 59, 10, 67,  6,  2, 29, 49,\n",
              "       77, 34, 10, 28,  0, 21, 57, 70, 32, 65,  4, 14, 69, 69, 15, 26, 63,\n",
              "       64, 47, 13, 39, 52, 71, 39, 62,  0, 62, 43, 79, 65, 28, 35, 83, 79,\n",
              "       34, 21, 51, 24, 43, 52,  3, 26, 32, 22, 52,  5, 61, 83, 81,  3,  1,\n",
              "       42, 46, 74, 47, 14, 46, 52,  5, 72, 83, 82, 14, 61, 12, 52, 53, 28,\n",
              "       76, 55, 21, 67, 56,  6, 74,  9, 63, 77, 19, 38, 75, 55, 53, 69, 78,\n",
              "       62, 65,  7, 47, 58, 19, 24, 47,  2, 19, 54,  9, 80, 53, 67, 74,  1,\n",
              "       34, 80, 11, 25, 70, 51, 72, 15, 63, 37, 28, 45, 53, 28, 40, 76, 17,\n",
              "       49, 82, 68, 71,  4, 70, 50, 61, 81, 25, 34, 62, 17, 26,  1, 15, 39,\n",
              "       66, 24, 29, 61, 74, 40,  3, 13, 36, 56, 63, 19, 74, 27, 37, 10, 40,\n",
              "       38, 16, 43, 81, 69, 46, 10, 78, 69, 30, 14, 13,  9,  5, 36, 44,  0,\n",
              "       33, 20, 54,  5, 43, 44, 52, 64, 43, 40, 82, 48, 73, 83, 82, 19, 62,\n",
              "       48, 66, 76, 18, 79, 21, 41, 44, 31, 78, 63, 14])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7SShbtIiPcl",
        "outputId": "cfae75f1-dc8b-492c-92e5-695b2db46da8"
      },
      "source": [
        "print(\"Given the input seq: \\n\")\n",
        "print(\"\".join(ind_to_char[input_example_batch[0]]))\n",
        "print('\\n')\n",
        "print(\"Next Char Predictions: \\n\")\n",
        "print(\"\".join(ind_to_char[sampled_indices ]))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Given the input seq: \n",
            "\n",
            "ord, hang me if ever I spake the words. My\n",
            "    accuser is my prentice; and when I did correct him for his fault\n",
            "    the other day, he did vow upon his knees he would be even with\n",
            "    me. I have good witness of this; therefore I beseech your\n",
            "    Majes\n",
            "\n",
            "\n",
            "Next Char Predictions: \n",
            "\n",
            "53di|k203|aKxF]Vd\n",
            "A\n",
            "26Wtd2Rld4BD3x9Kv}>(vrdmd.l(!DXvI.C\n",
            ":boGj&3nn4AhiV2N[pNg\n",
            "gRxjCJ}xI:Z>R[\"AG;['f}z\" QUsV3U['q}|3f1[]Cu`:la(s-hv8Mt`]nwgj)Vc8>V!8_-y]ls Iy0?oZq4hLCT]COu6X|mp&oYfz?Ig6A 4Nk>DfsO\"2Kah8sBL.OM5RznU.wnE32-'KS\n",
            "H9_'RS[iRO|Wr}|8gWku7x:PSFwh3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rQS5N4PkO2x"
      },
      "source": [
        "#Training the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEMm24BeJE99",
        "outputId": "714c6a42-f6d8-4ab7-e45d-94a28f667c2e"
      },
      "source": [
        "model.fit(dataset,epochs=40)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "169/169 [==============================] - 112s 639ms/step - loss: 2.9642\n",
            "Epoch 2/40\n",
            "169/169 [==============================] - 110s 640ms/step - loss: 2.1216\n",
            "Epoch 3/40\n",
            "169/169 [==============================] - 110s 640ms/step - loss: 1.7922\n",
            "Epoch 4/40\n",
            "169/169 [==============================] - 109s 638ms/step - loss: 1.5976\n",
            "Epoch 5/40\n",
            "169/169 [==============================] - 110s 642ms/step - loss: 1.4778\n",
            "Epoch 6/40\n",
            "169/169 [==============================] - 109s 636ms/step - loss: 1.3979\n",
            "Epoch 7/40\n",
            "169/169 [==============================] - 110s 641ms/step - loss: 1.3410\n",
            "Epoch 8/40\n",
            "169/169 [==============================] - 110s 642ms/step - loss: 1.2996\n",
            "Epoch 9/40\n",
            "169/169 [==============================] - 110s 641ms/step - loss: 1.2676\n",
            "Epoch 10/40\n",
            "169/169 [==============================] - 110s 642ms/step - loss: 1.2420\n",
            "Epoch 11/40\n",
            "169/169 [==============================] - 109s 638ms/step - loss: 1.2191\n",
            "Epoch 12/40\n",
            "169/169 [==============================] - 109s 639ms/step - loss: 1.2010\n",
            "Epoch 13/40\n",
            "169/169 [==============================] - 109s 636ms/step - loss: 1.1846\n",
            "Epoch 14/40\n",
            "169/169 [==============================] - 109s 639ms/step - loss: 1.1704\n",
            "Epoch 15/40\n",
            "169/169 [==============================] - 109s 638ms/step - loss: 1.1582\n",
            "Epoch 16/40\n",
            "169/169 [==============================] - 110s 641ms/step - loss: 1.1470\n",
            "Epoch 17/40\n",
            "169/169 [==============================] - 110s 643ms/step - loss: 1.1368\n",
            "Epoch 18/40\n",
            "169/169 [==============================] - 110s 644ms/step - loss: 1.1275\n",
            "Epoch 19/40\n",
            "169/169 [==============================] - 110s 645ms/step - loss: 1.1191\n",
            "Epoch 20/40\n",
            "169/169 [==============================] - 109s 636ms/step - loss: 1.1109\n",
            "Epoch 21/40\n",
            "169/169 [==============================] - 110s 642ms/step - loss: 1.1038\n",
            "Epoch 22/40\n",
            "169/169 [==============================] - 109s 637ms/step - loss: 1.0966\n",
            "Epoch 23/40\n",
            "169/169 [==============================] - 109s 638ms/step - loss: 1.0901\n",
            "Epoch 24/40\n",
            "169/169 [==============================] - 110s 641ms/step - loss: 1.0833\n",
            "Epoch 25/40\n",
            "169/169 [==============================] - 110s 642ms/step - loss: 1.0777\n",
            "Epoch 26/40\n",
            "169/169 [==============================] - 110s 642ms/step - loss: 1.0720\n",
            "Epoch 27/40\n",
            "169/169 [==============================] - 108s 629ms/step - loss: 1.0669\n",
            "Epoch 28/40\n",
            "169/169 [==============================] - 107s 624ms/step - loss: 1.0616\n",
            "Epoch 29/40\n",
            "169/169 [==============================] - 106s 621ms/step - loss: 1.0567\n",
            "Epoch 30/40\n",
            "169/169 [==============================] - 109s 638ms/step - loss: 1.0520\n",
            "Epoch 31/40\n",
            "169/169 [==============================] - 110s 640ms/step - loss: 1.0485\n",
            "Epoch 32/40\n",
            "169/169 [==============================] - 108s 633ms/step - loss: 1.0431\n",
            "Epoch 33/40\n",
            "169/169 [==============================] - 110s 642ms/step - loss: 1.0390\n",
            "Epoch 34/40\n",
            "169/169 [==============================] - 107s 627ms/step - loss: 1.0349\n",
            "Epoch 35/40\n",
            "169/169 [==============================] - 107s 622ms/step - loss: 1.0308\n",
            "Epoch 36/40\n",
            "169/169 [==============================] - 109s 639ms/step - loss: 1.0271\n",
            "Epoch 37/40\n",
            "169/169 [==============================] - 108s 628ms/step - loss: 1.0233\n",
            "Epoch 38/40\n",
            "169/169 [==============================] - 107s 622ms/step - loss: 1.0202\n",
            "Epoch 39/40\n",
            "169/169 [==============================] - 107s 624ms/step - loss: 1.0182\n",
            "Epoch 40/40\n",
            "169/169 [==============================] - 107s 623ms/step - loss: 1.0143\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6e20676210>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdSHCfmWkVpR"
      },
      "source": [
        "#Saving model as .h5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlSQexO_Kihm"
      },
      "source": [
        "model.save('shakespeare_gen1.h5') "
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-bh8SxPKzQd"
      },
      "source": [
        "from tensorflow.keras.models import load_model"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKGQx94-K0zB"
      },
      "source": [
        "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
        "\n",
        "model.load_weights('shakespeare_gen1.h5')\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dggbbxeokZMy"
      },
      "source": [
        "#Generating text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcSIFbF7K18L"
      },
      "source": [
        "def generate_text(model, start_seed,gen_size=100,temp=1.0):\n",
        "  '''\n",
        "  model: Trained Model to Generate Text\n",
        "  start_seed: Intial Seed text in string form\n",
        "  gen_size: Number of characters to generate\n",
        "\n",
        "  Basic idea behind this function is to take in some seed text, format it so\n",
        "  that it is in the correct shape for our network, then loop the sequence as\n",
        "  we keep adding our own predicted characters. Similar to our work in the RNN\n",
        "  time series problems.\n",
        "  '''\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_generate = gen_size\n",
        "\n",
        "  # Vecotrizing starting seed text\n",
        "  input_eval = [char_to_ind[s] for s in start_seed]\n",
        "\n",
        "  # Expand to match batch format shape\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty list to hold resulting generated text\n",
        "  text_generated = []\n",
        "\n",
        "  # Temperature effects randomness in our resulting text\n",
        "  # The term is derived from entropy/thermodynamics.\n",
        "  # The temperature is used to effect probability of next characters.\n",
        "  # Higher probability == lesss surprising/ more expected\n",
        "  # Lower temperature == more surprising / less expected\n",
        " \n",
        "  temperature = temp\n",
        "\n",
        "  # Here batch size == 1\n",
        "  model.reset_states()\n",
        "\n",
        "  for i in range(num_generate):\n",
        "\n",
        "      # Generate Predictions\n",
        "      predictions = model(input_eval)\n",
        "\n",
        "      # Remove the batch shape dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # Use a cateogircal disitribution to select the next character\n",
        "      predictions = predictions / temperature\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # Pass the predicted charracter for the next input\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      # Transform back to character letter\n",
        "      text_generated.append(ind_to_char[predicted_id])\n",
        "\n",
        "  return (start_seed + ''.join(text_generated))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpDjGWfPK7HK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1dc20d22-e0e9-4cdb-bc1c-9362e24592a1"
      },
      "source": [
        "print(generate_text(model,\"JULIET \",gen_size=800))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "JULIET AND             Exit. Soldiers.\n",
            "\n",
            "          Enter PROTEUS, VALENTINE, and SHYLOCK\n",
            "\n",
            "               EO-enter CHARMIAN, IACHIO, AUMERLE, CHILD and ATTENDANTS\n",
            "\n",
            "  CLARENCE. O, let me sing your Grace!\n",
            "    What, art thou to our conscience?\n",
            "  MENELAUS. If I can rush so well,\n",
            "    Impromish your equisore.\n",
            "  LEONTES. Come, come, pardon; let 't it down.\n",
            "  NESTOR. Your power great Priam shall.                  [Drum forth]\n",
            "  IACHIMO.                    Thank you so hung?  \n",
            "  AARON. How would you then depart at from your Grace?\n",
            "  GLOUCESTER. How bashful and Troy. O Caesar, I dare hear\n",
            "    Though given to sport, cross-gill'd and bloody wearth!\n",
            "  EDWARD. Even here unsadled Warwick give you jot;\n",
            "             The combin of the world able how\n",
            "                  As false against the fool.\n",
            "                  Ho! \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}